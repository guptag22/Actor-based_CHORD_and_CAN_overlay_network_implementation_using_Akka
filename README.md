# Homework 3 : 

### Description: Design and implement an Actor-based computational model for the Chord overlay network algorithm

## Overview
As part of this project a cloud simulation is implemented based on the Chord overlay network algorithm using the Akka typed actor model.



actors that simulate users who enter and retrieve data from the cloud, actors who represent servers (i.e., nodes) in the cloud that store the data, and case classes that represent data that are sent to and retrieved from the cloud. The entry point to your simulated cloud will be defined with a RESTful service using [Akka/HTTP](https://doc.akka.io/docs/akka-http/current/introduction.html). 



## Application Design

### Important Files



## Learning Akka
Actor models are widely used in high-performant cloud-based applications that are composed of distributed objects. Proposed in [the seminal paper in 1973](https://www.ijcai.org/Proceedings/73/Papers/027B.pdf) the Actor model is implemented for a variety of platforms and one of the most popular is a Lightbend's implementation called Akka. Your first step is to sign up for [Lightbend Academy](https://academy.lightbend.com) and to take short hands-on courses on Akka. Alternatively, you can read [the Akka documentation](https://doc.akka.io/docs/akka/current/typed/guide/introduction.html) that comes with many examples that you can easily copy and run on your laptops. You can choose the object-oriented (OO) model of the implementation, however, my advice is after you do exercises and you understand how the OO model works, you can switch to the typed, pure functional models to define behaviors of the actors as partial functions. Your code will be smaller, cleaner and much more elegant.

## Functionality
The input to your cloud simulator is the number of users, the number of the computers in the cloud - depending on your RAM and CPU it may be in millions, the minimum and the maximum number of requests per minute that each user actor can send, the duration of the simulation in minutes (more than one and less than 1000), the time marks (e.g., every three minutes during 20min simulation) when the system will capture a global state for testing (see the explanation below), the list of the items in a file (e.g., list of movies that include the title, the year, and the revenue), the ratio of read/write requests and the minimum and maximum percentages of the computing nodes that can fail within a pre-configured period of time. A read request will retrive an item from the cloud (e.g., a movie using its title/year) and a write RPC request will store an item in the cloud (e.g., uploading a movie using its title/year - of course the GBs of data that contain the actual movie content will not be uploaded). For additional 3% bonus for your homework, you can integrate your Scala simulator with a [statistical package called R](https://www.r-project.org/) to use its functions to implement the [accept/reject method](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2924739/) for sampling probabilistic distributions, which you can use to model various aspects in your simulator (e.g., the arrival of data items to store and their sizes or the failures of servers). As a result, your simulator is guided by probabilistic distributions with certain predefined parameters (e.g., the mean and the variance for the normal distribution) that you choose.

Thus, you will use a random generator to generate the number of requests for each actor that represents RPC clients using some probabilistic distribution of your choice. In fact, you can implement different distributions or select ones from the R package or some other open-source libraries. The semantics of the data (e.g., movies, books, simply records) does not matter - feel free to chose whatever you want. Once created, actors that represent RPC clients will generate and send data to the cloud endpoint(s), which will then use the algorithm CAN to deliver this data to the actors that simulate cloud servers to store or to retrieve the data. You will use a logging framework to log all requests sent from actors and received by the cloud and responses that are returned by the cloud actors.

### Functionality For Homework 3
For homework 3 students must implement the Chord algorithm using the convergent hashing that we studied in class, which is a realization of a DHT protocol that is described in the paper that is the mandatory reading material for this class: [Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications](https://pdos.csail.mit.edu/papers/chord:sigcomm01/chord_sigcomm.pdf). In your simulator, Chord will store key-value pairs and find the value associated with a key that is submitted by an actor, which simulates a user. To accomplish this task, Chord distributes actors that simulate cloud servers over a dynamic network of virtual nodes (you can assume one computer per node), and it implements a protocol for finding these objects once they have been placed in the overlay network. As you can imagine, there is an invisible network that connects cloud servers, which are simulated by the actors, however, these actors impose their own overlay network by using Chord to send messages directly to one another. Every node in this network is simulated as an actor for looking up keys for user actors and for determining which actors will serve as key stores. For the homework you do not have to deal with nodes failures and you do not need to model node joins and leaves as part of failures. This part is left for the course project.

Every key inserted into the DHT must be hashed, so that Chord will determine a node designated by the hashed value of the key, which is an m-bit unsigned integer. According to Chord, the the range of hash values for the DHT contains between 0 and (2 power m-1) inclusive. You can use a 128-bit (or a higher bit content) hash values produced by message digest algorithms such as MD5 or SHA-1 or some other hashing algorithms. You can make it a plugin feature in your simulator. An example of using MD5 in Scala is the following:
```java
import java.security.MessageDigest
def md5(s: String) = { MessageDigest.getInstance("MD5").digest(s.getBytes) }
val hashValue = md5("CS441_courseproject")
```

Actors that simulate nodes in the simulated cloud have the corresponding hash values that can be generated using unique names that your will assign to these nodes and they will be ordered based on those hashes (e.g., Node_123 => 0xDEADBEEF). Recall from the paper and the lecture that Chord orders all nodes in a ring, in which each node's successor is the node with the next highest hash value. To complete the circle, the node with the largest hash value has the node with the smallest hash value as its successor. Of course, if an item does not exist in the cloud, a corresponding "not found" message will be returned to the user actors in response to their get requests.

To locate the node at which a particular key-value pair is stored, the successor to the hash value of the key should be located. That is, to look up a key, a request is sent around the ring, so that each node (after determining that it does not hold the value itself) determines whether its successor is the owner of the key, and forwards the request to this successor. As part of Chord, the node asks its successor to find the successor of the key interatively, repeating the search procedure until the node is found or the error message is produced. This is done using the finger table at each node. Details are discussed in the paper and in my lecture. To recapitulate briefly, the number of entries in the finger table is equal to m, where m is defined above. Entry e in the finger table, where 0 <= e < m, is the node which the owner of the table believes is the successor for the (hash value + 2 power e). When some node actor N receives a request to find the successor of the key defined by its hash value, it first determines whether N or N's successor is the owner of the hash value, and if so, then N services the request or forwards it to the successor. Otherwise, N locates a node in its finger table such that this node has the largest hash smaller than the hash value, and forwards the request to this node actor. You can implement variations of this algorithm and describe it in your README.

As part of testing, you must capture the global state of the system in the YAML format and dump it. The time during which the dump occurs is defined as the input to the simulator program. In your simulated world, the simulator has the power to freeze the system and walk over all actors to obtain their local states and combine them into the global state that it can save into a file whose location is defined as part of the input. After dumping the state into the file, the simulator resumes the process.
